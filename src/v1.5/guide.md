# ğŸš€ Batch Processing Guide - Save 50% on OpenAI Costs!

## ğŸ“Š **Cost Comparison**

| Processing Mode | Cost | Speed | Best For |
|---|---|---|---|
| **Batch** | 50% cheaper | Up to 24 hours | Large-scale analysis (20+ recipes) |
| **Concurrent** | Standard rate | ~5-10 minutes | Small batches, immediate results |
| **Auto** | Smart choice | Varies | Let the system decide |

## ğŸ”§ **Installation**

```bash
# Install new dependencies
pip install rich>=13.7.0 aiofiles>=23.0.0

# Or update all requirements
pip install -r requirements.txt
```

## ğŸ’¡ **Quick Start Examples**

### **Option 1: Auto Mode (Recommended)**
Let the system choose the best processing mode:

```bash
python extract.py --collection-id 17854976980356429 --limit 100 --mode auto
```

### **Option 2: Batch Mode (50% Savings)**
Force batch processing for maximum cost savings:

```bash
python extract.py --collection-id 17854976980356429 --limit 200 --mode batch
```

### **Option 3: Concurrent Mode (Immediate Results)**
Use for small batches or when you need results right away:

```bash
python extract.py --collection-id 17854976980356429 --limit 20 --mode concurrent
```

## ğŸ“ˆ **Cost Analysis Examples**

### **Small Batch (20 recipes)**
- **Concurrent**: ~$0.045 (immediate)
- **Batch**: ~$0.023 (up to 24h)
- **Savings**: $0.022 (48% less)

### **Medium Batch (100 recipes)**
- **Concurrent**: ~$0.225 (30 minutes)
- **Batch**: ~$0.113 (up to 24h)
- **Savings**: $0.112 (50% less)

### **Large Batch (500 recipes)**
- **Concurrent**: ~$1.125 (2.5 hours)
- **Batch**: ~$0.563 (up to 24h)
- **Savings**: $0.562 (50% less) ğŸ’°

## ğŸ¯ **When to Use Each Mode**

### **Use Batch Mode When:**
- âœ… Processing 20+ recipes
- âœ… Cost savings are important
- âœ… You can wait up to 24 hours
- âœ… Running overnight or weekly analysis

### **Use Concurrent Mode When:**
- âœ… Processing < 20 recipes
- âœ… Need immediate results
- âœ… Testing new prompts
- âœ… Interactive analysis

### **Use Auto Mode When:**
- âœ… Unsure which to choose
- âœ… Want optimal cost/speed balance
- âœ… Different batch sizes each time

## ğŸ“Š **Progress Tracking Features**

The enhanced analyzer includes beautiful progress tracking:

```bash
ğŸ” Extracting 100 posts from collection 17854976980356429
âœ… Successfully extracted 100 posts

ğŸ’° Cost Analysis
â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Mode       â”ƒ        Cost â”ƒ Time           â”ƒ Notes                     â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Batch      â”‚      $0.113 â”‚ < 24 hours     â”‚ 50% discount, async       â”‚
â”‚ Concurrent â”‚      $0.225 â”‚ ~5-10 minutes  â”‚ Standard rate, immediate  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ Smart Recommendation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ ğŸ’¡ Recommendation: Use batch mode                                            â”ƒ
â”ƒ Potential savings: $0.11 (50.0%)                                            â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›

ğŸš€ Starting analysis in batch mode...
â ‹ Processing recipe detection batch: 45/100
```

## ğŸ“ **Extraction History Tracking**

Track your AI improvements over time:

```python
from foodiegram.extraction_history import ExtractionHistoryManager

# Initialize history manager
history = ExtractionHistoryManager()

# View recent runs
recent_runs = history.get_latest_runs(5)
for run in recent_runs:
    print(f"Run {run.run_id}: {run.success_rate:.1f}% success")

# Compare two runs
comparison = history.compare_runs("run_20250815_143022", "run_20250818_091234")
print(f"Success rate improved by {comparison.success_rate_change:.1f}%")
```

## ğŸ·ï¸ **English Translation Features**

The enhanced analyzer automatically translates Italian recipe terms:

### **Before (Duplicates):**
```json
{
  "vegetables": ["pomodoro", "tomato", "zucchine", "zucchini"],
  "key_ingredients": ["aglio", "garlic", "olio d'oliva", "olive oil"]
}
```

### **After (Clean English):**
```json
{
  "vegetables": ["tomato", "zucchini"],
  "key_ingredients": ["garlic", "olive oil"]
}
```

### **Supported Translations:**
- `pomodoro` â†’ `tomato`
- `zucchine` â†’ `zucchini`
- `aglio` â†’ `garlic`
- `cipolla` â†’ `onion`
- `basilico` â†’ `basil`
- `parmigiano` â†’ `parmesan`
- `olio d'oliva` â†’ `olive oil`
- `sale` â†’ `salt`
- `pepe` â†’ `pepper`

## ğŸ› ï¸ **Advanced Configuration**

### **Custom Batch Sizes**
```python
from foodiegram.analyzer import EnhancedRecipeAnalyzer

analyzer = EnhancedRecipeAnalyzer(
    openai_api_key="your-key",
    batch_size=1000,  # Custom batch size
    enable_caching=True  # Enable result caching
)
```

### **Custom Prompts**
Create custom prompt files:

```bash
# Create custom prompts
mkdir -p src/foodiegram/prompts
echo "Your custom detection prompt..." > src/foodiegram/prompts/is_recipe.md
echo "Your custom extraction prompt..." > src/foodiegram/prompts/extract_details.md
```

### **Programmatic Usage**
```python
from foodiegram.analyzer import EnhancedRecipeAnalyzer, ProcessingMode

analyzer = EnhancedRecipeAnalyzer(openai_api_key="your-key")

# Get cost estimates
estimate = analyzer.estimate_cost(posts, ProcessingMode.BATCH)
print(f"Estimated cost: ${estimate['estimated_total_cost']:.3f}")

# Get smart recommendations
recommendation = analyzer.get_processing_recommendation(posts)
print(f"Recommended mode: {recommendation['recommended_mode']}")

# Process with progress callback
def progress_callback(description: str, completed: int, total: int):
    print(f"{description}: {completed}/{total}")

recipes = analyzer.analyze_posts_batch_mode(
    posts=posts,
    processing_mode=ProcessingMode.BATCH,
    progress_callback=progress_callback
)
```

## ğŸ“Š **Monitoring Batch Jobs**

When using batch mode, you'll see real-time status updates:

```bash
ğŸš€ Starting analysis in batch mode...
ğŸ“ Created batch file with 200 requests
ğŸ“¤ Submitted batch job: batch_abc123xyz
â³ Polling batch abc123xyz for completion...
ğŸ“Š Batch abc123xyz status: in_progress
ğŸ“Š Processing recipe detection batch: 150/200
âœ… Batch abc123xyz completed in 3.2 minutes
```

## ğŸ¯ **Best Practices**

### **For Cost Optimization:**
1. **Use batch mode for 20+ recipes** - 50% savings
2. **Process overnight** - batch jobs often complete in 1-3 hours
3. **Enable caching** - avoid re-processing same recipes
4. **Batch similar collections** - group related recipe collections

### **For Speed Optimization:**
1. **Use concurrent mode for < 20 recipes**
2. **Enable result caching** - instant results for re-analysis
3. **Use auto mode** - smart choice based on batch size

### **For Quality Optimization:**
1. **Track extraction history** - monitor improvements
2. **Compare runs** - A/B test different prompts
3. **Review confidence scores** - focus on high-confidence extractions
4. **Customize prompts** - tailor to your specific content

## ğŸš¨ **Error Handling**

The system gracefully handles various errors:

### **Batch Failures:**
- Automatic fallback to concurrent processing
- Partial results if batch partially completes
- Detailed error logging and recovery

### **API Rate Limits:**
- Intelligent retry with exponential backoff
- Batch mode uses separate rate limits
- Progress tracking during delays

### **Network Issues:**
- Automatic retry for transient failures
- Partial result preservation
- Resume capability for large batches

## ğŸ“ˆ **Performance Monitoring**

### **View Analysis Summary:**
```bash
ğŸ“Š Analysis Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Metric                â”ƒ Value                 â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Total Posts Analyzed  â”‚ 100                   â”‚
â”‚ Recipes Found         â”‚ 67                    â”‚
â”‚ Non-Recipes          â”‚ 33                    â”‚
â”‚ Success Rate         â”‚ 67.0%                 â”‚
â”‚ Average Confidence   â”‚ 84.2%                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† Top Recipes by Confidence
1. Pasta with Garlic and Olive Oil (94.5%)
2. Zucchini Fritters (91.2%)
3. Tomato Basil Salad (89.7%)
```

### **Export History:**
```python
# Export detailed history for analysis
history.export_history(Path("extraction_analysis.json"))
```

## ğŸ‰ **Success Tips**

1. **Start with auto mode** - let the system optimize for you
2. **Monitor your costs** - check estimates before large batches
3. **Use progress tracking** - stay informed during processing
4. **Compare extraction runs** - continuously improve your prompts
5. **Enable caching** - speed up re-analysis and testing

## ğŸ†˜ **Troubleshooting**

### **"Batch job failed" Error:**
- Check your OpenAI API key and credits
- Verify network connectivity
- Try concurrent mode as fallback

### **"No recipes found" Result:**
- Review your collection ID
- Check if posts contain actual recipes
- Try lowering confidence threshold

### **Slow Processing:**
- Use batch mode for large collections
- Enable caching for repeated analysis
- Check your internet connection

## ğŸ¯ **Next Steps**

After implementing batch processing, you're ready for:
- **Task 1.2**: English Translation (âœ… Already included!)
- **Task 2.2**: History Tracking (âœ… Already included!)
- **Task 2.3**: Smart Tag Filtering
- **Task 3.1**: Production Deployment

---

**ğŸ’¡ Pro Tip:** Start with a small batch (20-50 recipes) in auto mode to get familiar with the system, then scale up to larger batches with batch mode for maximum savings!
